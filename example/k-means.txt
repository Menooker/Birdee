require Remote
require math
//5 1024 100000
const samples_per_iter=20
const round = 10
const verify_round = 2
const sample_num = 15000
const features = 4096
const step_size = 0.05
const threads_per_node =4
const batch_size = 15000
const staleness = 1
const K = 256
/*const round = 20
const verify_round = 2
const sample_num = 5000
const features = 4096
const step_size = 0.05
const threads_per_node =4
const batch_size = 5000
const staleness = 1
const K = 10*/

dim cur_round as int
dim time_total as int=GetClock()
dim time_calc as int
dim nodes as RemoteNode[]=StartNodesEx(5080,"slaves16.txt","memory16.txt")

println("working")
dim node_num as shared int=nodes.size()
dim thread_num as shared int=threads_per_node*node_num

dim feature_len as shared int
if (features) % 32 == 0 then
	feature_len = (features) / 32 * 32
else
	feature_len = (features) / 32 * 32 + 32
end

dim barrier_main as shared RBarrier=new RBarrier(thread_num+1)
dim barrier_internal as shared RBarrier=new RBarrier(node_num+1)
dim barrier_put as shared RBarrier=new RBarrier(node_num+1)
dim global_verify_miss_count as shared AtomicCounter=new AtomicCounter(0)
dim verify_miss_count as AtomicCounter=global_verify_miss_count
dim sema as shared RSemaphore=new RSemaphore(1)
dim global_cluster_counters as shared AtomicCounter[] global=new AtomicCounter[K] global

dim global_means as shared double[] global = new double[10] global
dim accu as shared RAccumulator=new RAccumulator(node_num,K*feature_len+K,global_means)


dim data_set1 as double[]
dim data_set2 as double[]

dim myparam as double[]
dim means as double[]
dim volatile sync2 as int
dim volatile sync1 as int
dim volatile sync3 as int
dim myfeature_len as int
dim mythreads as int
dim gmeans as double[] global
dim bar_main as RBarrier
dim bar_int as RBarrier
dim max_double as double
dim batch_num as int
dim volatile bar_file as int
dim cluster_num as int[]
dim clusters as double[][]

function my_rand() as int
	dim ran as int
	ran=rand(batch_size-K)
	if ran<0 then
		ran=-ran
	end
	return ran
end

sub put_initial(ds as double[],node_id as int)
unsafe
	dim i as int
	dim ran as int
	for i=node_id;i<K;i+=node_num
		ran=my_rand()
		gmeans[i*myfeature_len:(i+1)*myfeature_len]=ds[ran*myfeature_len:(ran+1)*myfeature_len]
	end
end

function putproc(id as var) as int
unsafe
	verify_miss_count=global_verify_miss_count
	mythreads=thread_num
	bar_main=barrier_main
	bar_int=barrier_internal
	dim i as int
	gmeans=global_means
	for i=0;i<K;i++
		cluster_counters[i]=global_cluster_counters[i]
	end

	dim put_step as int = 5
	dim node_n as int=node_num
	dim mlocal as double[]=new double[feature_len*put_step]
	//println("/home/ubuntu/shared/g"+id+".csv")
	dim file as CSVReader=new CSVReader("/home/ubuntu/shared/k-means-240000-16/synthetic_"+id+".csv")
	dim fl as int=feature_len
	dim ds as double[]
	dim j as int
	dim chunk_size as int=put_step*node_n
	//file.Skip(put_step*id)
	for batch_num=0;batch_num<sample_num/batch_size;batch_num++
		if batch_num %2==0 then
			ds=data_set1
		else
			ds=data_set2
		end
		for i=0;i<batch_size;i+=put_step
			for j=0;j<put_step;j++
				if(file.ReadLine(mlocal,j*fl)<0) then
					file.Reset()
					file.ReadLine(mlocal,j*fl)
				end
			end
			if i+put_step>batch_size then		
				ds[i*fl: batch_size*fl]=mlocal[0:fl*(batch_size-i)]
			else
				ds[i*fl: (i+put_step)*fl]=mlocal[0:fl*put_step]
			end
		end

		print("Put batch " + batch_num  + " done\n")
		bar_file@+=1
		if batch_num!=sample_num/batch_size-1 then
			for ;;
				if bar_file % (threads_per_node+1)==0 then
					break
				end
				Sleep(500)
			end
		end
	end
	file.Close()

	//barrier_put.Enter(-1)

end

sub put_matrix()
	dim tm as int=GetClock()
	dim i as int
	for i=0;i<node_num;i++
		nodes[i].CreateThread(putproc,i)
	end
	//barrier_put.Enter(-1)
	println("Put time"+(GetClock()-tm))
end

dim ii as int
dim jj as int
for ii=0;ii<K;ii++
	global_cluster_counters[ii]=new AtomicCounter(0)
end
dim time as int=GetClock()
put_matrix()

dim ttid as int=0

for ii=0;ii<node_num;ii++
	for jj=0;jj<threads_per_node;jj++
		nodes[ii].CreateThread(threadproc,ttid)
		ttid++
	end
end

barrier_main.Enter(-1)
println("Put initial centers ok")
dim time2 as int=GetClock()
for batch_num =0; batch_num<sample_num/batch_size;batch_num++
	for cur_round=0;cur_round<round;cur_round++
		barrier_main.Enter(-1)
		dim t as int
		t=GetClock()-time
		println("time "+ cur_round + " " +t)
		time=GetClock()
	end
	print("Batch "+batch_num+" Done\n")
end
dim time_middle as int=GetClock()
println("================\nLearning ok")
barrier_internal.Enter(-1)
println(verify_miss_count.Get()*10000)

println("calc time: "+ (time_middle-time2))
println("total time: "+ (GetClock()-time_total))
//file.Close()


dim local_cluster_sum as float[]
dim cluster_counters as AtomicCounter[]
dim volatile sync4 as int
function threadproc(id as var) as int
unsafe
	dim tid as int=id
	dim i as int
	dim j as int
	dim k as int
	dim st as int=tid % threads_per_node
	dim mround as int
	dim node_id as int=tid/threads_per_node
	dim mydata_set as double[]
	dim sum as double
	dim tmp as double
	dim dummy as int=thread_num
	dim means_base as int
	dim base as int
	dim tmp2 as double

	dim t1 as int
	dim t2 as int
	dim batch as int
	dim ran as int
	dim center as double[]=clusters[st]
	local_cluster_sum[0]=0
	means[0]=0
	center[0]=0
	cluster_counters[0]=cluster_counters[0]
	cluster_num[0]=cluster_num[0]
	mydata_set=center
	for batch=0; batch<sample_num/batch_size ; batch++
		if batch%2==0 then
			mydata_set=data_set1
		else
			mydata_set=data_set2
		end
		bar_file@+=1
		for ;;
			if bar_file % (threads_per_node+1)==0 then
				break
			end
		end
		if batch==0 then
			/*if st==0 then
				put_initial(mydata_set,node_id)
			end
			means[0:K*myfeature_len]=gmeans[0:K*myfeature_len]*/
			bar_main.Enter(-1)
		end

		for mround=0;mround<round;mround++
			for i=0;i<myfeature_len*K;i++
				center[i]=0
			end
			dim ttt as int
			if st ==0 then
				ttt=GetClock()
			end
			base=batch_size*st/threads_per_node*myfeature_len
			for i=0;i<batch_size/threads_per_node;i++
				sum=1.0f/0.0f
				means_base=0
				dim selected_k as int
				//calculate the distance from the data point to the centers
				for k=0;k<K;k++
					tmp=0
					for j=0;j<features;j++
						tmp2 = mydata_set[base+j]-means[means_base+j]
						tmp += tmp2*tmp2
					end
					if tmp<=sum then
						sum=tmp
						selected_k=k
					end
					means_base+=myfeature_len
				end
				cluster_num[selected_k]@+=1
				for j=0;j<features;j++
					center[selected_k*myfeature_len+j]+=mydata_set[base+j]
				end
				base+=myfeature_len
			end

			
			sync2@+=1
			if tid ==0 then
				println("CalcTime "+(GetClock()-ttt) + " " +node_id)
				for ;;
					if sync2 % threads_per_node==0 then
						break
					end
				end
			end
			//phase 4: sum up the local means
			//println("K4 "+mround+" "+st)
			if st==0 then
				for k=0;k<K;k++
					for j=0;j<features;j++
						local_cluster_sum[k*myfeature_len+j]=clusters[0][myfeature_len*k+j]
					end
				end
				for i=1;i<threads_per_node;i++
					for k=0;k<K;k++
						for j=0;j<features;j++
							local_cluster_sum[k*myfeature_len+j]+=clusters[i][myfeature_len*k+j]
						end
					end
				end
				for i=0;i<K;i++
					local_cluster_sum[K*myfeature_len+i]=cluster_num[i]
					cluster_num[i]=0
				end
				dummy=myfeature_len*K+K

				accu.Accumulatef(local_cluster_sum,-1)
//ttt=GetClock()
				means[0:dummy]=gmeans[0:dummy]
//println("SyncTime "+(GetClock()-ttt) + " " +node_id)
				for i=0;i<K;i+=1
					tmp=means[myfeature_len*K+i]
					/*if tid==0 && i<5 then
						println("C "+ i + " " +tmp)				
					end*/
					if tmp<0.1 then
						dummy=my_rand()
						means[i*myfeature_len:(i+1)*myfeature_len]=mydata_set[dummy*myfeature_len:(dummy+1)*myfeature_len]
					else
						for j=0;j<features;j++
							means[i*myfeature_len+j]= means[i*myfeature_len+j] / tmp
						end
					end

				end
			end
			bar_main.Enter(-1)
/*			sync1@+=1
			for ;;
				if sync1 % threads_per_node==0 then
					break
				end
			end
			

			sync3@+=1
			for ;;
				if sync3 % threads_per_node==0 then
					break
				end
			end*/
			if tid==0 then
				println(mround)
			end
		end
	end
	
	local_cluster_sum[st]=0
	base=batch_size*st/threads_per_node*myfeature_len
	for i=0;i<batch_size/threads_per_node;i++
		means_base=0
		sum=1.0f/0.0f
		//calculate the distance from the data point to the centers
		for k=0;k<K;k++
			tmp=0
			for j=0;j<features;j++
				tmp2 = mydata_set[base+j]-means[means_base+j]
				tmp += tmp2*tmp2
			end
			if tmp<=sum then
				sum=tmp
			end
			means_base+=myfeature_len
		end
		local_cluster_sum[st]+=sum
		base+=myfeature_len
	end
	
	sync4@+=1
	for ;;
		if sync4 % threads_per_node==0 then
			break
		end
	end
	if st==0 then
		for i=1;i<threads_per_node;i++
		    local_cluster_sum[0]+=local_cluster_sum[i]
		end
		println(local_cluster_sum[0])
		verify_miss_count.Inc(local_cluster_sum[0]/10000)
		bar_int.Enter(-1)
	end
end

sub RemoteInitialize()

	if (features) % 32 == 0 then
		myfeature_len = (features) / 32 * 32
	else
		myfeature_len = (features) / 32 * 32 + 32
	end
	means=new double[K * myfeature_len+K]
	data_set1=new double[myfeature_len*batch_size]
	//data_set2=new double[myfeature_len*batch_size]
	max_double=1.0/0.0
    cluster_num=new int[K]
	clusters=new double[16][K*myfeature_len] 
//fix-me : 16 -> node_num
	local_cluster_sum =new float[K * myfeature_len+K]
	cluster_counters=new AtomicCounter[K]
end


