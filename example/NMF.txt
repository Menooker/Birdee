require Remote
require math

//distributed parallel version of http://blog.csdn.net/lilyth_lilyth/article/details/8958147

const round = 20

const sample_num = 5000
//48000/2
const threads_per_node = 4
const batch_size = 5000
//48000/2
const staleness = 1
const alpha=0.02f
const beta=0.02f
const features=17770
const matK=32
const split_features=1
const P_init=0.75f
const Q_init=0.75f

/*const sample_num = 512*1024/16
const threads_per_node = 4
const batch_size = 512*1024/16
const staleness = 1
const alpha=0.002f
const beta=0.002f
const features=1024*8
const matK=32
const split_features=1
const P_init=1.0f
const Q_init=0.1f*/

dim cur_round as int
dim time_total as int=GetClock()
dim time_calc as int
dim nodes as RemoteNode[]=StartNodesEx(5090,"slaves16.txt","memory16.txt")

print("working with "+nodes.size()+" nodes\n")
dim node_num as shared int=nodes.size()
dim thread_num as shared int=threads_per_node*node_num
dim myK_len as int
dim feature_len as shared int
if (features) % 32 == 0 then
	feature_len = (features) / 32 * 32
else
	feature_len = (features) / 32 * 32 + 32
end

if (matK) % 32 == 0 then
	myK_len = matK
else
	myK_len = (matK) / 32 * 32 + 32
end

dim barrier_main as shared RBarrier=new RBarrier(thread_num+1)
dim barrier_internal as shared RBarrier=new RBarrier(node_num+1)
dim barrier_put as shared RBarrier=new RBarrier(node_num+1)

dim n2 as int=feature_len * thread_num * sample_num
dim global_gradient as shared double[] global = new double[10] global
dim data_set1 as float[]
dim data_set2 as float[]

dim accu as shared RAccumulator=new RAccumulator(node_num,features*myK_len,global_gradient)

dim P as float[]
dim Q as float[]
//Q[k][features]

dim gradient as float[][]
dim volatile sync2 as int
dim volatile sync1 as int
dim myfeature_len as int
dim mythreads as int
dim gparam as double[] global
dim bar_main as RBarrier
dim bar_int as RBarrier
dim batch_num as int
dim volatile bar_file as int

sub CopyAndTrunc(src as double[], start_s as int, dest as float[], start_d as int , len as int)
unsafe
	dim d as float[]=dest
	dim s as double[]=src
	dim i as int
	dim l as int=len
	for i=0;i<len;i++
		d[start_d+i]=s[start_s+i]
	end
end

function putproc(id as var) as int
unsafe
	mythreads=thread_num
	bar_main=barrier_main
	bar_int=barrier_internal

	dim node_n as int=node_num
	//dim mlocal as double[]=new double[feature_len*put_step]
	//println("/home/ubuntu/shared/g"+id+".csv")
	dim file as CSVReader=new CSVReader("/home/ubuntu/shared_bin/netflix16/netflix.txt."+id)
	//println("/home/ubuntu/shared/NMF512k/NMF.txt."+id)
	//dim file as CSVReader=new CSVReader("/home/ubuntu/shared/NMF512k/NMF.txt."+id)	
	dim fl as int=feature_len
	dim ds as float[]
	dim i as int
	dim j as int
	dim d as double
	//file.Skip(put_step*id)
	for batch_num=0;batch_num<sample_num/batch_size;batch_num++
		if batch_num %2==0 then
			ds=data_set1
		else
			ds=data_set2
		end
		for i=0;i<batch_size;i+=1
			for j=0;j<features;j++
				d=file.ReadDouble()
				ds[i*fl+j]=d		
			end
		end
		print("Put batch " + batch_num  + " done\n")
		bar_file@+=1
		if batch_num!=sample_num/batch_size-1 then
			for ;;
				if bar_file % (threads_per_node+1)==0 then
					break
				end
				Sleep(500)
			end
		end
	end
	file.Close()

	//barrier_put.Enter(-1)

end

sub put_matrix()
	dim tm as int=GetClock()
	dim i as int
	for i=0;i<node_num;i++
		nodes[i].CreateThread(putproc,i)
	end
	//barrier_put.Enter(-1)
	println("Put time"+(GetClock()-tm))
end

dim time as int=GetClock()
put_matrix()

dim ttid as int=0
dim ii as int
dim jj as int
for ii=0;ii<node_num;ii++
	for jj=0;jj<threads_per_node;jj++
		nodes[ii].CreateThread(threadproc,ttid)
		ttid++
	end
end

barrier_main.Enter(-1)
dim time2 as int=GetClock()
for batch_num =0; batch_num<sample_num/batch_size;batch_num++
	for cur_round=0;cur_round<round;cur_round++
		//put_matrix()

		barrier_main.Enter(-1)
		dim t as int
		t=GetClock()-time
		println("time "+ cur_round + " " +t)
		time=GetClock()
	end
	print("Batch "+batch_num+" Done\n")
end


println("calc time: "+ (GetClock()-time2))
println("total time: "+ (GetClock()-time_total))
//file.Close()
for ii=0;ii<node_num;ii++
	nodes[ii].Close()
end



sub zero_gradient(idx as int)
unsafe
	dim i as int
	for i=0;i<features*myK_len;i++
		gradient[idx][i]=0
	end
end


dim buf as double[]
function threadproc(id as var) as int
unsafe
	dim tid as int=id
	dim i as int
	dim j as int
	dim k as int
	dim st as int=tid % threads_per_node
	dim mround as int
	dim node_id as int=tid/threads_per_node
	dim mydata_set as float[]
	dim mygradient as float[]=gradient[st]
	
	dim local_gradient_sum as float[]=gradient[0]
	dim myp as float[]=P
	dim myq as float[]=Q
	mygradient[0]=0
	dim dot as float
	dim h as float
	dim ran as int
	dim dummy as int=thread_num

dim tm as int
	dim base as int
	dim ibase as int
	dim tmp as float
	dim t1 as int
	dim t2 as int
	dim batch as int
	dim pindex as int
	dim qindex as int
	dim tmp2 as float
	mydata_set=data_set1
	mydata_set[0]=mydata_set[0]
	dim start_t as int =GetClock()
	dim size as int=batch_size/threads_per_node
	dim objv as float=0
	dim objv2 as float=0
	ibase=batch_size*st/threads_per_node
	dim stepp as float=alpha
	dim stepq as float=beta
	for batch=0; batch<sample_num/batch_size ; batch++
		if batch%2==0 then
			mydata_set=data_set1
		else
			mydata_set=data_set2
		end
		bar_file@+=1
		for ;;
			if bar_file % (threads_per_node+1)==0 then
				break
			end
		end
		if batch==0 then
			bar_main.Enter(-1)
			for k=0;k<matK;k++
				myp[pindex + k]=P_init
			end
			qindex=0
			for j=0;j<features;j++
				for k=0;k<matK;k++
					myq[qindex+k]=Q_init
				end
				pindex+=matK
			end
		end
		for mround=0;mround<round;mround++
			zero_gradient(st)
			
			
			pindex=ibase*matK
			//phase 3: calculate the gradient on the set of data
			//println("K3 "+mround+" "+st)
			tm=GetClock()
			dim tile as int
			
			base=batch_size*st/threads_per_node*myfeature_len
			for i=0;i<size;i++
				qindex=0
				objv=0.0f
				for j=0;j<features;j++
					//Q[k][j]
					dot=0
					for k=0;k<matK;k++
						dot+=myp[pindex + k]*myq[qindex+k]
					end
					dot= mydata_set[base+j] - dot
					objv+= dot*dot
					for k=0;k<matK;k++
						myp[pindex+k]+= stepp * dot * myq[qindex+k]
						mygradient[qindex+k]+= stepq * dot * myp[pindex+k]						
					end
					//*/
					
					/*for k=0;k<matK;k++
						tmp=myp[pindex + k]
						tmp2=myq[qindex+k]
						myp[pindex + k]+= stepp * (2.0f * dot * tmp2 - stepq * tmp) 
						mygradient[qindex+k] += stepp * (2.0f * dot * tmp - stepq * tmp2)
					end
					//*/
					qindex+=myK_len
				end
				objv2+= objv
				for k=0;k<matK;k++
					if myp[pindex + k]<0 then
						myp[pindex + k]=0				
					end
				end
				pindex+=matK
				base+=myfeature_len
			end
			stepp=alpha
			stepq=beta
			//tm=GetClock()
			sync2@+=1
			if st==0 then
				for ;;
					if sync2 % threads_per_node==0 then
						break
					end
					Sleep(10)
				end
			end
			if tid==0 then
				println( "Loss="+ objv2/size + " "+ (GetClock()-tm) +" "+node_id)
				objv2=0
				println(mygradient[123])
			end
			//phase 4: sum up the local gradient
			//println("K4 "+mround+" "+st)
			if st==0 then
				for i=1;i<threads_per_node;i++
						for j=0;j<features*myK_len;j++
							local_gradient_sum[j]+=gradient[i][j]
						end
				end
				tm=GetClock()
				accu.Accumulatef(local_gradient_sum,-1)
				//println( "accu"+ (GetClock()-tm) +" "+node_id)
				buf[0:features*myK_len]=global_gradient[0:features*myK_len]
				for j=0;j<features*myK_len;j++
						myq[j]+=buf[j]/size
						if myq[i]<0 then
							myq[i]=0
						end
				end

			end
			bar_main.Enter(-1)
		end
	end
	//println("Time used ="+ (GetClock()-start_t))
end

sub RemoteInitialize()

	if (features) % 32 == 0 then
		myfeature_len = (features) / 32 * 32
	else
		myfeature_len = (features) / 32 * 32 + 32
	end
	if (matK) % 32 == 0 then
		myK_len = matK
	else
		myK_len = (matK) / 32 * 32 + 32
	end
	
	buf=new double[features*myK_len]
	gradient=new float[threads_per_node][features*myK_len]
	data_set1=new float[myfeature_len*batch_size]
	//data_set2=new float[myfeature_len*batch_size]
	Q=new float[features*myK_len]
	P=new float[batch_size*matK]
	//bar_file=new RBarrier(threads_per_node+1)
end


