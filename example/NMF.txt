require Remote
require math

//distributed parallel version of http://blog.csdn.net/lilyth_lilyth/article/details/8958147

const samples_per_iter=20
const round = 10
const verify_round = 2
const sample_num = 8192
const threads_per_node = 4
const batch_size = 8192
const staleness = 1
const alpha=0.01f
const beta=0.01f
const features=4096
const matK=32
const split_features=1

dim cur_round as int
dim time_total as int=GetClock()
dim time_calc as int
dim nodes as RemoteNode[]=StartNodesEx(5080,"slaves.txt","memory.txt")

print("working with "+nodes.size()+" nodes\n")
dim node_num as shared int=nodes.size()
dim thread_num as shared int=threads_per_node*node_num
dim myK_len as int
dim feature_len as shared int
if (features) % 32 == 0 then
	feature_len = (features) / 32 * 32
else
	feature_len = (features) / 32 * 32 + 32
end

if (matK) % 32 == 0 then
	myK_len = matK
else
	myK_len = (matK) / 32 * 32 + 32
end

dim barrier_main as shared RBarrier=new RBarrier(thread_num+1)
dim barrier_internal as shared RBarrier=new RBarrier(node_num+1)
dim barrier_put as shared RBarrier=new RBarrier(node_num+1)

dim n2 as int=feature_len * thread_num * sample_num
dim global_gradient as shared double[] global = new double[10] global
dim data_set1 as float[]
dim data_set2 as float[]

dim accu as shared RAccumulator=new RAccumulator(node_num,features*myK_len,global_gradient)

dim P as float[]
dim Q as float[]
//Q[k][features]

dim gradient as float[][]
dim volatile sync2 as int
dim volatile sync1 as int
dim myfeature_len as int
dim mythreads as int
dim gparam as double[] global
dim bar_main as RBarrier
dim bar_int as RBarrier
dim batch_num as int
dim volatile bar_file as int

sub CopyAndTrunc(src as double[], start_s as int, dest as float[], start_d as int , len as int)
unsafe
	dim d as float[]=dest
	dim s as double[]=src
	dim i as int
	dim l as int=len
	for i=0;i<len;i++
		d[start_d+i]=s[start_s+i]
	end
end

function putproc(id as var) as int
unsafe
	mythreads=thread_num
	bar_main=barrier_main
	bar_int=barrier_internal

	dim put_step as int = 5
	dim node_n as int=node_num
	dim mlocal as double[]=new double[feature_len*put_step]
	//println("/home/ubuntu/shared/g"+id+".csv")
	dim file as CSVReader=new CSVReader("/home/ubuntu/shared_bin/petuum/bosen/app/NMF/sample/data/NMF.csv."+id)
	dim fl as int=feature_len
	dim ds as float[]
	dim i as int
	dim j as int
	dim chunk_size as int=put_step*node_n
	//file.Skip(put_step*id)
	for batch_num=0;batch_num<sample_num/batch_size;batch_num++
		if batch_num %2==0 then
			ds=data_set1
		else
			ds=data_set2
		end
		for i=0;i<batch_size;i+=put_step
			for j=0;j<put_step;j++
				if(file.ReadLine(mlocal,j*fl)<0) then
					file.Reset()
					file.ReadLine(mlocal,j*fl)
				end
			end
			if i+put_step>batch_size then
				CopyAndTrunc(mlocal,0,ds,i*fl,	fl*(batch_size-i))			
				//ds[i*fl: batch_size*fl]=mlocal[0:fl*(batch_size-i)]
			else
				CopyAndTrunc(mlocal,0,ds,i*fl,	fl*put_step)
				//ds[i*fl: (i+put_step)*fl]=mlocal[0:fl*put_step]
			end
		end
		print("Put batch " + batch_num  + " done\n")
		bar_file@+=1
		if batch_num!=sample_num/batch_size-1 then
			for ;;
				if bar_file % (threads_per_node+1)==0 then
					break
				end
				Sleep(500)
			end
		end
	end
	file.Close()

	//barrier_put.Enter(-1)

end

sub put_matrix()
	dim tm as int=GetClock()
	dim i as int
	for i=0;i<node_num;i++
		nodes[i].CreateThread(putproc,i)
	end
	//barrier_put.Enter(-1)
	println("Put time"+(GetClock()-tm))
end

dim time as int=GetClock()
put_matrix()

dim ttid as int=0
dim ii as int
dim jj as int
for ii=0;ii<node_num;ii++
	for jj=0;jj<threads_per_node;jj++
		nodes[ii].CreateThread(threadproc,ttid)
		ttid++
	end
end

barrier_main.Enter(-1)
dim time2 as int=GetClock()
for batch_num =0; batch_num<sample_num/batch_size;batch_num++
	for cur_round=0;cur_round<round;cur_round++
		//put_matrix()

		barrier_main.Enter(-1)
		dim t as int
		t=GetClock()-time
		println("time "+ cur_round + " " +t)
		time=GetClock()
	end
	print("Batch "+batch_num+" Done\n")
end


println("calc time: "+ (GetClock()-time2))
println("total time: "+ (GetClock()-time_total))
//file.Close()
for ii=0;ii<node_num;ii++
	nodes[ii].Close()
end


function myrand() as int
	dim p as int=rand(batch_size-samples_per_iter)
	if p<0 then
		p=-p
	end
	return p
end


sub zero_gradient(idx as int)
unsafe
	dim i as int
	for i=0;i<features*myK_len;i++
		gradient[idx][i]=0
	end
end


dim buf as double[]
function threadproc(id as var) as int
unsafe
	dim tid as int=id
	dim i as int
	dim j as int
	dim k as int
	dim st as int=tid % threads_per_node
	dim mround as int
	dim node_id as int=tid/threads_per_node
	dim mydata_set as float[]
	dim mygradient as float[]=gradient[st]
	
	dim local_gradient_sum as float[]=gradient[0]
	dim myp as float[]=P
	dim myq as float[]=Q
	mygradient[0]=0
	dim dot as float
	dim h as float
	dim ran as int
	dim dummy as int=thread_num

	dim base as int
	dim ibase as int
	dim tmp as float
	dim t1 as int
	dim t2 as int
	dim batch as int
	dim pindex as int
	dim qindex as int
	dim tmp2 as float
	mydata_set=data_set1
	mydata_set[0]=mydata_set[0]
	dim start_t as int =GetClock()
	dim size as int=batch_size/threads_per_node
	for batch=0; batch<sample_num/batch_size ; batch++
		if batch%2==0 then
			mydata_set=data_set1
		else
			mydata_set=data_set2
		end
		bar_file@+=1
		for ;;
			if bar_file % (threads_per_node+1)==0 then
				break
			end
		end
		if batch==0 then
			bar_main.Enter(-1)		
		end
		for mround=0;mround<round;mround++
			zero_gradient(st)
			
			ibase=batch_size*st/threads_per_node
			
			//phase 3: calculate the gradient on the set of data
			//println("K3 "+mround+" "+st)
			dim tm as int
			tm=GetClock()
			dim tile as int
			dim feature_start as int
			dim feature_end as int
			pindex=ibase*matK
			base=batch_size*st/threads_per_node*myfeature_len
			for i=0;i<size;i++
				dot=0
				qindex=myK_len*feature_start
				for j=0;j<features;j++
					//Q[k][j]
					for k=0;k<matK;k++
						dot+=myp[pindex + k]*myq[qindex+k]
					end
					dot=mydata_set[base+j] - dot
					for k=0;k<matK;k++
						myp[pindex+k]+= alpha * dot * myq[qindex+k]
						mygradient[qindex+k]+=beta * dot * myp[pindex+k]
					end
					//*/
					
					/*for k=0;k<matK;k++
						tmp=myp[pindex + k]
						tmp2=myq[qindex+k]
						myp[pindex + k]+= alpha * (2.0f * dot * tmp2 - beta * tmp)
						mygradient[qindex+k] += alpha * (2.0f * dot * tmp - beta * tmp2)
					end
					//*/
					qindex+=myK_len
				end
				pindex+=matK
				base+=myfeature_len
			end
			println( ""+ (GetClock()-tm) +" "+id)
			//tm=GetClock()
			sync2@+=1
			for ;;
				if sync2 % threads_per_node==0 then
					break
				end
			end
			//phase 4: sum up the local gradient
			//println("K4 "+mround+" "+st)
			if st==0 then
				if mround % staleness ==0 then
					for i=1;i<threads_per_node;i++
						for j=0;j<features*myK_len;j++
							local_gradient_sum[j]+=gradient[i][j]
						end
					end
				end

				accu.Accumulatef(local_gradient_sum,-1)
				buf[0:features*myK_len]=global_gradient[0:features*myK_len]
				for j=0;j<features*myK_len;j++
						myq[j]+=buf[j]
						if myq[i]<0 then
							myq[i]=0
						end
				end

			end
			bar_main.Enter(-1)
		end
	end
	println("Time used ="+ (GetClock()-start_t))
end

sub RemoteInitialize()

	if (features) % 32 == 0 then
		myfeature_len = (features) / 32 * 32
	else
		myfeature_len = (features) / 32 * 32 + 32
	end
	if (matK) % 32 == 0 then
		myK_len = matK
	else
		myK_len = (matK) / 32 * 32 + 32
	end
	
	buf=new double[features*myK_len]
	gradient=new float[threads_per_node][features*myK_len]
	data_set1=new float[myfeature_len*batch_size]
	data_set2=new float[myfeature_len*batch_size]
	Q=new float[features*myK_len]
	P=new float[batch_size*matK]
	//bar_file=new RBarrier(threads_per_node+1)
end


