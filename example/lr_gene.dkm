require Remote
require math

const samples_per_iter=20
const round = 20
const verify_round = 7
const sample_num = 737
const features = 22283
const step_size = 0.1
const threads_per_node = 4
const batch_size = 737
const staleness = 1
const reg = 0.01

dim cur_round as int
dim time_total as int=GetClock()
dim time_calc as int
dim nodes as RemoteNode[]=StartNodesEx(5090,"slaves.txt","memory.txt")

println("working")
dim node_num as shared int=nodes.size()
dim thread_num as shared int=threads_per_node*node_num

dim feature_len as shared int
if (features+1) % 32 == 0 then
	feature_len = (features+1) / 32 * 32
else
	feature_len = (features+1) / 32 * 32 + 32
end

dim barrier_main as shared RBarrier=new RBarrier(thread_num+1)
dim barrier_internal as shared RBarrier=new RBarrier(node_num+1)
dim barrier_put as shared RBarrier=new RBarrier(node_num+1)
dim global_verify_miss_count as shared AtomicCounter=new AtomicCounter(0)
dim global_verify_positive_count as shared AtomicCounter=new AtomicCounter(0)
dim global_verify_false_count as shared AtomicCounter=new AtomicCounter(0)
dim verify_miss_count as AtomicCounter=global_verify_miss_count
dim verify_positive_count as AtomicCounter=global_verify_positive_count
dim verify_false_count as AtomicCounter=global_verify_false_count
dim param as shared double[] global = new double[10] global

dim n2 as int=feature_len * thread_num * sample_num
dim global_gradient as shared double[] global = new double[10] global
dim accu as shared RAccumulator=new RAccumulator(node_num,feature_len,global_gradient)
dim data_set1 as double[]
dim data_set2 as double[]

dim myparam as double[]
dim gradient as double[][]
dim volatile sync2 as int
dim volatile sync1 as int
dim myfeature_len as int
dim mythreads as int
dim gparam as double[] global
dim bar_main as RBarrier
dim bar_int as RBarrier
dim local_dataset as double[][]
dim batch_num as int
dim volatile bar_file as int

function putproc(id as var) as int
unsafe
	verify_miss_count=global_verify_miss_count
	verify_positive_count =global_verify_positive_count
	verify_false_count =global_verify_false_count
	mythreads=thread_num
	gparam=param
	bar_main=barrier_main
	bar_int=barrier_internal

	dim put_step as int = 5
	dim node_n as int=node_num
	dim mlocal as double[]=new double[feature_len*put_step]
	//println("/home/ubuntu/shared/g"+id+".csv")
	dim file as CSVReader=new CSVReader("/home/ubuntu/shared/g"+id+".csv")
	dim fl as int=feature_len
	dim ds as double[]
	dim i as int
	dim j as int
	dim chunk_size as int=put_step*node_n
	//file.Skip(put_step*id)
	for batch_num=0;batch_num<sample_num/batch_size;batch_num++
		if batch_num %2==0 then
			ds=data_set1
		else
			ds=data_set2
		end
		for i=0;i<batch_size;i+=put_step
			for j=0;j<put_step;j++
				if(file.ReadLine(mlocal,j*fl)<0) then
					file.Reset()
					file.ReadLine(mlocal,j*fl)
				end
			end
			if i+put_step>batch_size then		
				ds[i*fl: batch_size*fl]=mlocal[0:fl*(batch_size-i)]
			else
				ds[i*fl: (i+put_step)*fl]=mlocal[0:fl*put_step]
			end
		end
		print("Put batch " + batch_num  + " done\n")
		bar_file@+=1
		if batch_num!=sample_num/batch_size-1 then
			for ;;
				if bar_file % (threads_per_node+1)==0 then
					break
				end
				Sleep(500)
			end
		end
	end
	file.Close()

	//barrier_put.Enter(-1)

end

sub put_matrix()
	dim tm as int=GetClock()
	dim i as int
	for i=0;i<node_num;i++
		nodes[i].CreateThread(putproc,i)
	end
	//barrier_put.Enter(-1)
	println("Put time"+(GetClock()-tm))
end

dim time as int=GetClock()
put_matrix()
dim time2 as int=GetClock()
dim ttid as int=0
dim ii as int
dim jj as int
for ii=0;ii<node_num;ii++
	for jj=0;jj<threads_per_node;jj++
		nodes[ii].CreateThread(threadproc,ttid)
		ttid++
	end
end

for batch_num =0; batch_num<sample_num/batch_size;batch_num++
	for cur_round=0;cur_round<round;cur_round++
		//put_matrix()

		barrier_main.Enter(-1)
		dim t as int
		t=GetClock()-time
		println("time "+ cur_round + " " +t)
		time=GetClock()
	end
	print("Batch "+batch_num+" Done\n")
end

println("================\nLearning ok, now verify")
for ;cur_round<round+verify_round;cur_round++
	//put_matrix()

	barrier_main.Enter(-1)
	t=GetClock()-time
	println("time1 "+ t)
	time=GetClock()
end

dim precision as double= 1- verify_miss_count.Get()/(verify_positive_count.Get()+0.001)
dim recall as double= 1 - verify_false_count.Get()/ (verify_round*batch_size*nodes.size()- verify_positive_count.Get()+0.001)
println("precision=1-"+verify_miss_count.Get()+"/"+verify_positive_count.Get()+"="+ precision)
println("recall="+ recall)
println("calc time: "+ (GetClock()-time2))
println("total time: "+ (GetClock()-time_total))
//file.Close()
//gets()


function myrand() as int
	dim p as int=rand(batch_size-samples_per_iter)
	if p<0 then
		p=-p
	end
	return p
end


sub zero_gradient(idx as int)
	dim i as int
	for i=0;i<myfeature_len;i++
		gradient[idx][i]=0
	end
end

function threadproc(id as var) as int
unsafe
	dim tid as int=id
	dim i as int
	dim j as int
	dim k as int
	dim st as int=tid % threads_per_node
	dim mround as int
	dim node_id as int=tid/threads_per_node
	dim mydata_set as double[] 
	gradient[0][0]=0
	dim dot as double
	dim h as double
	dim ran as int
	dim dummy as int=thread_num

	dim base as int

	dim t1 as int
	dim t2 as int
	dim batch as int
	for i=0;i<features;i++
		myparam[i]=0.01	
	end
	for batch=0; batch<sample_num/batch_size ; batch++
		if batch%2==0 then
			mydata_set=data_set1
		else
			mydata_set=data_set2
		end
		bar_file@+=1
		for ;;
			if bar_file % (threads_per_node+1)==0 then
				break
			end
		end
		for mround=0;mround<round;mround++
	//dim tm1 as int=GetClock()		
			zero_gradient(st)
			base=batch_size*st/threads_per_node*myfeature_len
			//phase 3: calculate the gradient on the set of data
			//println("K3 "+mround+" "+st)

			for i=0;i<batch_size/threads_per_node;i++
				dot=0
				for j=0;j<features;j++
					dot+=myparam[j]*mydata_set[base+j]
				end
				h=1/(1+exp(-dot))
				dim delta as double=mydata_set[base+features]-h
				for j=0;j<features;j++
					gradient[st][j]+= step_size * delta * mydata_set[base+j]
				end
				base+=myfeature_len
			end
			sync2@+=1
			for ;;
				if sync2 % threads_per_node==0 then
					break
				end
			end
	//t1+= GetClock()-tm1
			//phase 4: sum up the local gradient
			//println("K4 "+mround+" "+st)
			if st==0 then
				if mround % staleness ==0 then
					for i=1;i<threads_per_node;i++
						for j=0;j<features;j++
							gradient[0][j]+=gradient[i][j]
						end
					end
					//global_gradient[node_id * myfeature_len : (node_id+1) * myfeature_len]=gradient[0][0:myfeature_len]	
				end
				accu.Accumulate(gradient[0],-1)
				dim buf as double[]
				buf=gradient[1]
				buf[0 : myfeature_len]=global_gradient[0 : myfeature_len]
				for j=0;j<features;j++
					myparam[j]+= (buf[j]- step_size*reg*myparam[j])/batch_size
				end
			end

			bar_main.Enter(-1)

		end
	end

	/*myparam[feature_len*st/threads_per_node : feature_len*(st+1)/threads_per_node]=gparam[feature_len*st/threads_per_node : feature_len*(st+1)/threads_per_node]
	sync2@+=1
	for ;;
		if sync2 % threads_per_node==0 then
			break
		end
	end*/

	//now verify the parameter vector
	dim total_round as int=verify_round+round
	for mround=0;mround<verify_round;mround++
		//phase 1: copy the data set
		ran=myrand()

		//phase 2: calculate the misses on the set of data
		base=ran*myfeature_len
		for i=0;i<samples_per_iter;i++
			dot=0
			for j=0;j<features;j++
				dot+=myparam[j]*mydata_set[base+j]
			end
			h=1/(1+exp(-dot))
			if mydata_set[base+features]==1.0 then
				verify_positive_count.Inc(1)
				if h<0.5 then
					verify_miss_count.Inc(1)
				end
			elseif h>=0.5 then
				verify_false_count.Inc(1)			
			end
			base+=myfeature_len
		end
		bar_main.Enter(-1)
	end
end

sub RemoteInitialize()
	
	if (features+1) % 32 == 0 then
		myfeature_len = (features+1) / 32 * 32
	else
		myfeature_len = (features+1) / 32 * 32 + 32
	end
	gradient=new double[threads_per_node][myfeature_len]
	myparam=new double[myfeature_len]
	data_set1=new double[myfeature_len*batch_size]
	data_set2=new double[myfeature_len*batch_size]
	//bar_file=new RBarrier(threads_per_node+1)
end


